import os
import chromadb
from datetime import datetime
import uuid
import time
from memory_priority import MemoryPriority  # <-- ×”×—×™×‘×•×¨ ×œ×ž×•×“×•×œ ×”×“×™×¨×•×’ ×©×™×¦×¨× ×•

# ×”×’×“×¨×•×ª × ×ª×™×‘×™×
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "..", "data", "brain_db")

# ××ª×—×•×œ ×ž×¡×“ ×”× ×ª×•× ×™×
client = chromadb.PersistentClient(path=DB_PATH)

# ×™×¦×™×¨×ª ××•×¡×¤×™× (Collections)
facts_collection = client.get_or_create_collection("facts")
episodes_collection = client.get_or_create_collection("episodes")

def save_memory(text, category="general", importance="medium"):
    """
    ×©×•×ž×¨ ×¢×•×‘×“×” ×¢× ×“×™×¨×•×’ ×—×©×™×‘×•×ª.
    importance: 'high', 'medium', 'low'
    """
    try:
        facts_collection.add(
            documents=[text],
            metadatas=[{
                "category": category, 
                "timestamp": time.time(), # ×©×•×ž×¨×™× ×›-Unix Timestamp ×œ×—×™×©×•×‘×™ ×“×¢×™×›×”
                "importance": importance,
                "access_count": 0
            }],
            ids=[str(uuid.uuid4())]
        )
        return f"× ×©×ž×¨ ×‘×–×™×›×¨×•×Ÿ ({importance})."
    except Exception as e:
        print(f"Error saving memory: {e}")
        return f"×©×’×™××” ×‘×–×™×›×¨×•×Ÿ: {e}"

def save_episode(description, user_emotion, ai_emotion, importance="medium"):
    """×©×•×ž×¨ ×—×•×•×™×” ×¨×’×©×™×ª"""
    try:
        episodes_collection.add(
            documents=[description],
            metadatas=[{
                "user_emotion": user_emotion,
                "ai_emotion": ai_emotion,
                "importance": importance,
                "timestamp": time.time(),
                "readable_time": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "access_count": 0
            }],
            ids=[str(uuid.uuid4())]
        )
        print(f"ðŸ§  × ×¦×¨×‘×” ×—×•×•×™×”: {description}")
        return "×ª×™×¢×“×ª×™ ××ª ×”×—×•×•×™×”."
    except Exception as e:
        print(f"Error saving episode: {e}")
        return f"×©×’×™××” ×‘×ª×™×¢×•×“: {e}"

def retrieve_memory(query, n_results=5):
    """
    ×©×œ×™×¤×ª ×–×™×›×¨×•×Ÿ ×—×›×ž×” ×”×ž×©×ª×ž×©×ª ×‘-MemoryPriority
    """
    try:
        # 1. ×©×œ×™×¤×” ×’×•×œ×ž×™×ª ×ž-ChromaDB (×™×•×ª×¨ ×ª×•×¦××•×ª ×ž×ž×” ×©×¦×¨×™×š, ×›×“×™ ×©× ×¡× ×Ÿ)
        raw_results = facts_collection.query(query_texts=[query], n_results=n_results + 3)
        
        memories_to_sort = []
        
        # 2. ×”×ž×¨×” ×œ×¤×•×¨×ž×˜ ×©×”×ž×ž×™×™×Ÿ ×©×œ× ×• ×ž×‘×™×Ÿ
        if raw_results['documents'] and raw_results['documents'][0]:
            docs = raw_results['documents'][0]
            metas = raw_results['metadatas'][0]
            distances = raw_results['distances'][0] # Chroma ×ž×—×–×™×¨ ×ž×¨×—×§ (×”×¤×•×š ×œ×“×ž×™×•×Ÿ)
            ids = raw_results['ids'][0]

            for i in range(len(docs)):
                # ×”×ž×¨×ª ×ž×¨×—×§ ×œ×¦×™×•×Ÿ ×“×ž×™×•×Ÿ (0-1) ×‘×§×™×¨×•×‘
                similarity = max(0, 1 - distances[i])
                
                mem_obj = {
                    "content": docs[i],
                    "metadata": metas[i],
                    "id": ids[i]
                }
                # ×©×•×ž×¨×™× ×›×–×•×’ (×–×™×›×¨×•×Ÿ, ×¦×™×•×Ÿ ×“×ž×™×•×Ÿ)
                memories_to_sort.append((mem_obj, similarity))

        # 3. ×©×™×ž×•×© ×‘-MemoryPriority ×œ×ž×™×•×Ÿ ×—×›×
        # ×–×” ×™×™×ª×Ÿ ×¢×“×™×¤×•×ª ×œ×–×™×›×¨×•× ×•×ª ×—×©×•×‘×™× ×•×—×“×©×™× ×¢×œ ×¤× ×™ ×¡×ª× ×“×•×ž×™×
        sorted_memories = MemoryPriority.sort_memories(memories_to_sort)
        
        # 4. ×¢×“×›×•×Ÿ ×ž×•× ×” ×©×™×ž×•×© (Access Count) ×œ×–×™×›×¨×•× ×•×ª ×©× ×‘×—×¨×•
        # (×–×” ×ž×—×–×§ ×–×™×›×¨×•× ×•×ª ×©×ž×©×ª×ž×©×™× ×‘×”× ×”×¨×‘×”)
        top_memories = sorted_memories[:n_results]
        for mem in top_memories:
            _update_access_count(mem['id'], mem['metadata'])

        # 5. ×¤×¨×ž×•×˜ ×”×˜×§×¡×˜ ×œ-GPT
        combined_context = []
        for mem in top_memories:
            meta = mem['metadata']
            imp_marker = "â­" if meta.get('importance') == 'high' else ""
            
            # ×× ×–×” timestamp ×™×©×Ÿ (×ž×—×¨×•×–×ª) ××• ×—×“×© (float), × ×¡×” ×œ×”×¦×™×’ ×§×¨×™×
            ts = meta.get('timestamp')
            date_str = "×‘×¢×‘×¨"
            try:
                if isinstance(ts, float):
                    date_str = datetime.fromtimestamp(ts).strftime('%d/%m')
                else:
                    date_str = str(ts).split('T')[0]
            except: pass

            combined_context.append(f"[{date_str}]{imp_marker} {mem['content']}")
                
        if not combined_context:
            return "××™×Ÿ ×–×™×›×¨×•×Ÿ ×¨×œ×•×•× ×˜×™."
            
        return "\n".join(combined_context)

    except Exception as e:
        print(f"Error retrieving memory: {e}")
        return ""

def _update_access_count(doc_id, metadata):
    """×¤×•× ×§×¦×™×™×ª ×¢×–×¨ ×œ×¢×“×›×•×Ÿ ×ž×•× ×” ×”×¦×¤×™×•×ª ×‘×–×™×›×¨×•×Ÿ"""
    try:
        new_count = metadata.get('access_count', 0) + 1
        metadata['access_count'] = new_count
        facts_collection.update(ids=[doc_id], metadatas=[metadata])
    except:
        pass