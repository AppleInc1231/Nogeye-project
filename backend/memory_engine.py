import json
import os
import datetime
from openai import OpenAI
from dotenv import load_dotenv

# ×˜×¢×™× ×ª ×”×’×“×¨×•×ª
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "..", "data")
MEMORY_PATH = os.path.join(DATA_DIR, "memory.json")
ENV_PATH = os.path.join(BASE_DIR, ".env")
load_dotenv(ENV_PATH)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ×•×•×“× ×©×”×ª×™×§×™×™×” ×§×™×™××ª
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

def _load_memory():
    """×˜×•×¢×Ÿ ××ª ×§×•×‘×¥ ×”×–×™×›×¨×•×Ÿ ×‘×‘×˜×—×”"""
    if not os.path.exists(MEMORY_PATH):
        return {
            "conversations": [],
            "facts": {},
            "preferences": {}
        }
    try:
        with open(MEMORY_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"conversations": [], "facts": {}, "preferences": {}}

def _save_memory_file(data):
    """×©×•××¨ ××ª ×§×•×‘×¥ ×”×–×™×›×¨×•×Ÿ"""
    try:
        with open(MEMORY_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving memory file: {e}")

def save_memory(content, importance="medium"):
    """
    ×©××™×¨×” ×™×“× ×™×ª ×©×œ ×–×™×›×¨×•×Ÿ (×¤×§×•×“×ª REMEMBER)
    ×©×•××¨ ××ª ×–×” ×›×¢×•×‘×“×” (Fact)
    """
    data = _load_memory()
    timestamp = str(datetime.datetime.now())
    
    # ××ª×—×•×œ ×× ×—×¡×¨
    if "facts" not in data:
        data["facts"] = {}

    # ×™×¦×™×¨×ª ××¤×ª×— ×™×™×—×•×“×™
    key = f"manual_{timestamp}"
    data["facts"][key] = content
    
    _save_memory_file(data)
    return f"×–×›×¨×ª×™: {content}"

def retrieve_memory(query, n_results=5):
    """
    ×©×œ×™×¤×ª ×–×™×›×¨×•×Ÿ ×¨×œ×•×•× ×˜×™ ×œ×©×™×—×”.
    ××—×–×™×¨ ×©×™×œ×•×‘ ×©×œ ×”×¢×•×‘×“×•×ª ×”××—×¨×•× ×•×ª + ×§×¦×ª ××”×©×™×—×” ×”××—×¨×•× ×”.
    """
    data = _load_memory()
    
    # 1. ×©×œ×™×¤×ª ×¢×•×‘×“×•×ª (××¦×™×’ ××ª ×”-20 ×”××—×¨×•× ×•×ª ×›×“×™ ×©×™×”×™×” ×”×§×©×¨ ×¨×—×‘ ×¢×œ ×”××©×ª××©)
    facts_list = list(data.get("facts", {}).values())
    # ×œ×•×§×—×™× ××ª ×”-20 ×”××—×¨×•× ×•×ª
    recent_facts = facts_list[-20:]
    facts_str = "\n".join([f"- {f}" for f in recent_facts])
    
    # 2. ×©×œ×™×¤×ª ×”×©×™×—×” ×”××—×¨×•× ×” (Context) - ××¦×™×’ ×¢×“ 10 ×”×•×“×¢×•×ª ×œ×©×œ×™×¤×” ××”×™×¨×”
    # (×”×”×™×¡×˜×•×¨×™×” ×”××œ××” ×©×œ ×”-50 × ×©×œ×—×ª ×‘× ×¤×¨×“ ×‘-wake_chat)
    recent_convo = data.get("conversations", [])[-10:]
    convo_str = json.dumps(recent_convo, ensure_ascii=False)
    
    return f"User Facts:\n{facts_str}\n\nRecent Interaction Snippet:\n{convo_str}"

def save_episode(description, user_emotion, ai_emotion, importance="medium"):
    """×©××™×¨×ª ××¤×™×–×•×“×” ××©××¢×•×ª×™×ª - ×”×›× ×” ×œ×¢×ª×™×“"""
    # ×›×¨×’×¢ × ×©××•×¨ ××ª ×–×” ×›×¢×•×‘×“×”, ×‘×¢×ª×™×“ ××¤×©×¨ ×œ×”×¨×—×™×‘ ×œ××¡×“ ×•×§×˜×•×¨×™
    content = f"Episode: {description} (User: {user_emotion}, AI: {ai_emotion})"
    save_memory(content, importance)
    return "× ×©××¨ ×‘×™×•××Ÿ ×”××™×¨×•×¢×™×."

# --- ×”×× ×•×¢ ×”×—×“×©: ××•×¤×˜×™××™×–×¦×™×” ×—×›××” (Consolidation) ---
def consolidate_memory():
    """
    ×”×¤×•× ×§×¦×™×” ×”×–×• ×¨×¦×” ×‘×–××Ÿ '×—×œ×™××”'.
    ×”×™× ×œ×•×§×—×ª ××ª ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×” ×”××¨×•×›×”,
    ××–×§×§×ª ××× ×” ×¢×•×‘×“×•×ª ×—×“×©×•×ª ×¢×œ ×”××©×ª××©,
    ×•××•×—×§×ª ××ª ×”××œ×œ ×”××™×•×ª×¨ ×›×“×™ ×œ×©××•×¨ ×¢×œ ×§×•×‘×¥ ×§×˜×Ÿ ×•××”×™×¨.
    """
    data = _load_memory()
    conversations = data.get("conversations", [])
    
    # ×¡×£ ×”× ×™×§×•×™: ×× ×™×© ×¤×—×•×ª ×-60 ×”×•×“×¢×•×ª, ×œ× × ×•×’×¢×™× ×›×œ×•× (×›×“×™ ×©×™×”×™×” ×¨×¦×£)
    if len(conversations) < 1:
        return
        
    print("ğŸ§  ××‘×¦×¢ ×ª×”×œ×™×š ×’×™×‘×•×© ×–×™×›×¨×•×Ÿ (Learning)...")
    
    # ×—×œ×•×§×”: ××ª ×”×™×©× ×™× ×× ×ª×—×™×, ××ª ×”-50 ×”××—×¨×•× ×™× ×©×•××¨×™× ×›××• ×©×”× (×–×™×›×¨×•×Ÿ ×¢×‘×•×“×”)
    to_analyze = conversations[:-50] 
    to_keep = conversations[-50:]
    
    # ×”×•×¤×›×™× ××ª ×”×©×™×—×•×ª ×”×™×©× ×•×ª ×œ×˜×§×¡×˜ ×‘×©×‘×™×œ ×”-AI
    conversation_text = json.dumps(to_analyze, ensure_ascii=False)
    
    # ×”×¤×¨×•××¤×˜ ×œ×–×™×§×•×§ ×¢×•×‘×“×•×ª
    prompt = f"""
    Analyze this conversation log between AI and User (Maor).
    Extract clear, distinct FACTS about the user (preferences, hobbies, work, pets, location, plans, fears).
    Ignore small talk ("hello", "how are you", "search for X").
    
    Return the output as a clean list of facts in Hebrew.
    If nothing new was learned about the user personally, return "NO_NEW_INFO".
    
    Log:
    {conversation_text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a memory consolidation engine. Extract facts."},
                {"role": "user", "content": prompt}
            ]
        )
        
        result = response.choices[0].message.content.strip()
        
        if "facts" not in data:
            data["facts"] = {}

        if "NO_NEW_INFO" not in result:
            timestamp = str(datetime.datetime.now())
            # ×”×•×¡×¤×ª ×”×¢×•×‘×“×•×ª ×”×—×“×©×•×ª
            new_facts = result.split("\n")
            for fact in new_facts:
                clean_fact = fact.replace("- ", "").strip()
                if clean_fact and len(clean_fact) > 5:
                    # ××¤×ª×— ×™×™×—×•×“×™ ×œ×›×œ ×¢×•×‘×“×”
                    key = f"{timestamp}_{clean_fact[:10]}"
                    data["facts"][key] = clean_fact
                    print(f"ğŸ’¡ × ×œ××“ ×•× ×©××¨: {clean_fact}")
        
        # ××—×™×§×ª ×”×”×™×¡×˜×•×¨×™×” ×”×™×©× ×” ×•×©××™×¨×”
        data["conversations"] = to_keep
        _save_memory_file(data)
        print("âœ… ×”×–×™×›×¨×•×Ÿ ×¢×‘×¨ ××•×¤×˜×™××™×–×¦×™×”: ×”×•×“×¢×•×ª ×™×©× ×•×ª × ×•×§×•, ×¢×•×‘×“×•×ª × ×©××¨×•.")
        
    except Exception as e:
        print(f"Memory Consolidation Error: {e}")

# ×œ×”×¤×¢×œ×” ×™×“× ×™×ª ×œ×‘×“×™×§×”
if __name__ == "__main__":
    consolidate_memory()